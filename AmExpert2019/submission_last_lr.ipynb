{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures, RobustScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.special import logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "campaign_data=pd.read_csv('campaign_data.csv')\n",
    "coupon_item_mapping=pd.read_csv('coupon_item_mapping.csv')\n",
    "customer_demographics=pd.read_csv('customer_demographics.csv')\n",
    "customer_transaction_data=pd.read_csv('customer_transaction_data.csv')\n",
    "item_data=pd.read_csv('item_data.csv')\n",
    "test=pd.read_csv('test_QyjYwdj.csv')\n",
    "submission = pd.read_csv('sample_submission_Byiv0dS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#campaign_data, customer_demographics customer_transaction_data\n",
    "# item_data, coupon_item_mapping\n",
    "train = pd.read_csv(file.get(\"train\"))#\n",
    "test = pd.read_csv(file.get(\"test\"))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupon_item_mapping = pd.read_csv(file.get(\"coupon_item_mapping\"))#No\n",
    "item_data = pd.read_csv(file.get(\"item_data\"))# may be yes\n",
    "customer_transaction_data = pd.read_csv(file.get(\"customer_transaction_data\"))#may be yes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_data = pd.read_csv(file.get(\"campaign_data\"))#\n",
    "customer_demographics = pd.read_csv(file.get(\"customer_demographics\"))#\n",
    "submission = pd.read_csv(file.get(\"sample_submission_Byiv0dS\"))\n",
    "data = pd.concat([train, test], sort=False).reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltr = len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(campaign_data, on='campaign_id')#  campaign_data\n",
    "data['start_date'] = pd.to_datetime(data['start_date'], dayfirst=True)\n",
    "data['end_date'] = pd.to_datetime(data['end_date'], dayfirst=True)\n",
    "data['campaign_type'] = pd.Series(data['campaign_type'].factorize()[0]).replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customer_demographics\n",
    "customer_demographics['no_of_children'] = customer_demographics['no_of_children'].replace('3+', 3).astype(float)\n",
    "customer_demographics['family_size'] = customer_demographics['family_size'].replace('5+', 3).astype(float)\n",
    "customer_demographics['marital_status'] = pd.Series(customer_demographics['marital_status'].factorize()[0]).replace(-1, np.nan)\n",
    "customer_demographics['age_range'] = pd.Series(customer_demographics['age_range'].factorize()[0]).replace(-1, np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rented\n",
    "rented_mean = customer_demographics.groupby(\"customer_id\")['rented'].mean().to_dict()\n",
    "data['rented_mean'] = data['customer_id'].map(rented_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# income_bracket\n",
    "income_bracket_sum = customer_demographics.groupby(\"customer_id\")['income_bracket'].sum().to_dict()\n",
    "data['income_bracket_sum'] = data['customer_id'].map(income_bracket_sum)\n",
    "# age_range\n",
    "age_range_mean = customer_demographics.groupby(\"customer_id\")['age_range'].mean().to_dict()\n",
    "data['age_range_mean'] = data['customer_id'].map(age_range_mean)\n",
    "# family_size\n",
    "family_size_mean = customer_demographics.groupby(\"customer_id\")['family_size'].mean().to_dict()\n",
    "data['family_size_mean'] = data['customer_id'].map(family_size_mean)\n",
    "# no_of_children\n",
    "no_of_children_mean = customer_demographics.groupby(\"customer_id\")['no_of_children'].mean().to_dict()\n",
    "data['no_of_children_mean'] = data['customer_id'].map(no_of_children_mean)\n",
    "no_of_children_count = customer_demographics.groupby(\"customer_id\")['no_of_children'].count().to_dict()\n",
    "data['no_of_children_count'] = data['customer_id'].map(no_of_children_count)\n",
    "# marital_status\n",
    "marital_status_count = customer_demographics.groupby(\"customer_id\")['marital_status'].count().to_dict()\n",
    "data['marital_status_count'] = data['customer_id'].map(marital_status_count)\n",
    "#############################################################################\n",
    "# customer_transaction_data\n",
    "customer_transaction_data['date'] = pd.to_datetime(customer_transaction_data['date'])\n",
    "# quantity\t\n",
    "quantity_mean = customer_transaction_data.groupby(\"customer_id\")['quantity'].mean().to_dict()\n",
    "data['quantity_mean'] = data['customer_id'].map(quantity_mean)\n",
    "#coupon_discount\n",
    "coupon_discount_mean = customer_transaction_data.groupby(\"customer_id\")['coupon_discount'].mean().to_dict()\n",
    "data['coupon_discount_mean'] = data['customer_id'].map(coupon_discount_mean)\n",
    "# other_discount\n",
    "other_discount_mean = customer_transaction_data.groupby(\"customer_id\")['other_discount'].mean().to_dict()\n",
    "data['other_discount_mean'] = data['customer_id'].map(other_discount_mean)\n",
    "# day\n",
    "customer_transaction_data['day'] = customer_transaction_data.date.dt.day\n",
    "date_day_mean = customer_transaction_data.groupby(\"customer_id\")['day'].mean().to_dict()\n",
    "data['date_day_mean'] = data['customer_id'].map(date_day_mean)\n",
    "#coupon_item_mapping, item_data\n",
    "coupon_item_mapping = coupon_item_mapping.merge(item_data, how = 'left', on = 'item_id')\n",
    "coupon_item_mapping['brand_type'] = pd.Series(coupon_item_mapping['brand_type'].factorize()[0]).replace(-1, np.nan)\n",
    "coupon_item_mapping['category'] = pd.Series(coupon_item_mapping['category'].factorize()[0]).replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = coupon_item_mapping.groupby(\"coupon_id\")['category'].mean().to_dict()\n",
    "data['category_mean'] = data['coupon_id'].map(category)\n",
    "category = coupon_item_mapping.groupby(\"coupon_id\")['category'].count().to_dict()\n",
    "data['category_count'] = data['coupon_id'].map(category)\n",
    "category = coupon_item_mapping.groupby(\"coupon_id\")['category'].nunique().to_dict()\n",
    "data['category_nunique'] = data['coupon_id'].map(category)\n",
    "category = coupon_item_mapping.groupby(\"coupon_id\")['category'].max().to_dict()\n",
    "data['category_max'] = data['coupon_id'].map(category)\n",
    "category = coupon_item_mapping.groupby(\"coupon_id\")['category'].min().to_dict()\n",
    "data['category_min'] = data['coupon_id'].map(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_mean = coupon_item_mapping.groupby(\"coupon_id\")['brand'].mean().to_dict()\n",
    "data['brand_mean'] = data['coupon_id'].map(brand_mean)\n",
    "brand_mean = coupon_item_mapping.groupby(\"coupon_id\")['brand'].count().to_dict()\n",
    "data['brand_count'] = data['coupon_id'].map(brand_mean)\n",
    "brand_mean = coupon_item_mapping.groupby(\"coupon_id\")['brand'].min().to_dict()\n",
    "data['brand_min'] = data['coupon_id'].map(brand_mean)\n",
    "brand_mean = coupon_item_mapping.groupby(\"coupon_id\")['brand'].max().to_dict()\n",
    "data['brand_max'] = data['coupon_id'].map(brand_mean)\n",
    "brand_mean = coupon_item_mapping.groupby(\"coupon_id\")['brand'].nunique().to_dict()\n",
    "data['brand_nunique'] = data['coupon_id'].map(brand_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selling_price\n",
    "selling_price_mean = customer_transaction_data.groupby(\"customer_id\")['selling_price'].mean().to_dict()\n",
    "data['selling_price_mean'] = data['customer_id'].map(selling_price_mean)\n",
    "selling_price_mean = customer_transaction_data.groupby(\"customer_id\")['selling_price'].sum().to_dict()\n",
    "data['selling_price_sum'] = data['customer_id'].map(selling_price_mean)\n",
    "selling_price_mean = customer_transaction_data.groupby(\"customer_id\")['selling_price'].min().to_dict()\n",
    "data['selling_price_min'] = data['customer_id'].map(selling_price_mean)\n",
    "selling_price_mean = customer_transaction_data.groupby(\"customer_id\")['selling_price'].max().to_dict()\n",
    "data['selling_price_max'] = data['customer_id'].map(selling_price_mean)\n",
    "selling_price_mean = customer_transaction_data.groupby(\"customer_id\")['selling_price'].nunique().to_dict()\n",
    "data['selling_price_nunique'] = data['customer_id'].map(selling_price_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = [i for i in data.columns if i not in ['id','redemption_status','start_date','end_date']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = ['campaign_id','coupon_id','campaign_type','rented_mean','income_bracket_sum','age_range_mean','family_size_mean',\n",
    " 'no_of_children_mean',\n",
    " 'no_of_children_count',\n",
    " 'marital_status_count',\n",
    " 'quantity_mean',\n",
    " 'coupon_discount_mean',\n",
    " 'other_discount_mean',\n",
    " 'date_day_mean',\n",
    " 'category_mean',\n",
    " 'category_nunique',\n",
    " 'category_max',\n",
    " 'category_min',\n",
    " 'brand_mean',\n",
    " 'brand_max',\n",
    " 'brand_nunique',\n",
    " 'selling_price_mean',\n",
    " 'selling_price_min',\n",
    " 'selling_price_nunique']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data['redemption_status'].notnull()]\n",
    "test = data[data['redemption_status'].isnull()]\n",
    "dummies = pd.get_dummies(data[train_cols].fillna(0), columns=train_cols, drop_first=True, sparse=True)\n",
    "train_ohe = dummies.iloc[:train.shape[0], :]\n",
    "test_ohe = dummies.iloc[train.shape[0]:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_ohe.shape)\n",
    "print(test_ohe.shape)\n",
    "train_ohe = train_ohe.sparse.to_coo().tocsr()\n",
    "test_ohe = test_ohe.sparse.to_coo().tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "def run_cv_model(train, test, target, model_fn, params={}, eval_fn=None, label='model'):\n",
    "    kf = StratifiedKFold(n_splits=10, shuffle = True, random_state = 228)\n",
    "    fold_splits = kf.split(train, target)\n",
    "    cv_scores = []\n",
    "    pred_full_test = 0\n",
    "    pred_train = np.zeros((train.shape[0]))\n",
    "    i = 1\n",
    "    for dev_index, val_index in fold_splits:\n",
    "        print('Started ' + label + ' fold ' + str(i) + '/5')\n",
    "        dev_X, val_X = train[dev_index], train[val_index]\n",
    "        dev_y, val_y = target[dev_index], target[val_index]\n",
    "        params2 = params.copy()\n",
    "        pred_val_y, pred_test_y = model_fn(dev_X, dev_y, val_X, val_y, test, params2)\n",
    "        pred_full_test = pred_full_test + pred_test_y\n",
    "        pred_train[val_index] = pred_val_y\n",
    "        if eval_fn is not None:\n",
    "            cv_score = eval_fn(val_y, pred_val_y)\n",
    "            cv_scores.append(cv_score)\n",
    "            print(label + ' cv score {}: {}'.format(i, cv_score))\n",
    "        i += 1\n",
    "    print('{} cv scores : {}'.format(label, cv_scores))\n",
    "    print('{} cv mean score : {}'.format(label, np.mean(cv_scores)))\n",
    "    print('{} cv std score : {}'.format(label, np.std(cv_scores)))\n",
    "    pred_full_test = pred_full_test / 10.0\n",
    "    results = {'label': label,\n",
    "              'train': pred_train, 'test': pred_full_test,\n",
    "              'cv': cv_scores}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLR(train_X, train_y, test_X, test_y, test_X2, params):\n",
    "    print('Train LR')\n",
    "    model = LogisticRegression(**params)\n",
    "    model.fit(train_X, train_y)\n",
    "    print('Predict 1/2')\n",
    "    pred_test_y = logit(model.predict_proba(test_X)[:, 1])\n",
    "    print('Predict 2/2')\n",
    "    pred_test_y2 = logit(model.predict_proba(test_X2)[:, 1])\n",
    "    return pred_test_y, pred_test_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['redemption_status'].values\n",
    "lr_params = {'solver': 'lbfgs','C': 1.8,'max_iter' : 2000,'class_weight':'balanced'}\n",
    "results = run_cv_model(train_ohe, test_ohe, target, runLR, lr_params, auc, 'lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = 2\n",
    "sub = 3\n",
    "name = f\"day_{day}_sub_{sub}\"\n",
    "tmp = dict(zip(test.id.values, results['test']))\n",
    "answer1 = pd.DataFrame()\n",
    "answer1['id'] = test.id.values\n",
    "answer1['redemption_status'] = answer1['id'].map(tmp)\n",
    "answer1.to_csv(f'{name}.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
